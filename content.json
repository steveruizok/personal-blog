{"pages":[{"slug":"about","content":"\nMy name is Steve Ruiz and I'm a developer and interaction designer in London, currently working with creative tools. I build lots of prototypes. Sometimes those prototypes turn into products.\n\n## My Work\n\nI'm currently focusing on [tldraw](https://tldraw.com), a white-boarding application and an [engine](https://github.com/tldraw/tldraw) for applications that render React components onto a canvas interface. You can [sponsor my work](https://github.com/sponsors/steveruizok) on Github!\n\nI've previously worked with [Play](https://www.createwithplay.com/), helping to design a mobile-first design application for iOS. Before that, I was creating educational content for [Framer](https://framer.com/) and a user experience architect at [Inviqa](https://inviqa.com/). I've also worked with [ClearScore](https://www.clearscore.com/), [Phenomen Films](https://www.phenomentrust.org/), and plenty of shorter contracts, too.\n\n## Open Source\n\nI maintain a few open source projects:\n\n- [tldraw](https://tldaw.com/) is a tiny little drawing app.\n- [perfect-freehand](https://github.com/steveruizok/perfect-freehand) is a library for drawing freehand lines.\n- [perfect-arrows](https://github.com/steveruizok/perfect-arrows) is a library for drawing arrows between points and shapes. It made for some fun [tweet threads](https://twitter.com/steveruizok/status/1283139008499986437).\n- [state-designer](https://state-designer.com/) is a state management library with its own [visual design environment](https://ide.state-designer.com/). It's based on state charts and is great for prototyping.\n\n## Education\n\nI have my Masters degree in Fine Art from the University of Chicago. If you're curious, you can see more of my artwork [here](https://steveruizart.com).\n\n## Contact\n\nThe best way to contact me is on [twitter](https://twitter.com/steveruizok).\n","data":{"title":"About"},"index":0},{"slug":"archive","content":"","data":{"title":"Archive"},"index":1},{"slug":"index","content":"","data":{},"index":2}],"posts":[{"index":0,"slug":"dead-zone","content":"\nThis is another post about improving user experience in applications that involve dragging shapes around on a canvas, or in a [zoom-ui](/posts/zoom-ui). This post will cover implementing a \"dead zone\": a minimum distance needed before a shape will begin to drag.\n\nA dead zone is very useful to prevent \"accidental drags\" during clicks. Without a dead zone, a pixel or two of movement can result in a change to a shape's position. This especially common on touch devices or when using a stylus, and it can be very frustrating for users.\n\nBut have no fearâ€”a dead zone can fix it.\n\n> ðŸ‘‹ Just want to look at some code? [Click here](https://codesandbox.io/s/dead-zone-example-1zkw9) for the CodeSandbox.\n\n## Get Your Dragging Right First\n\nThis post is a follow-up to my [post](/posts/perfect-dragging) about the correct way to calculate where a dragging shape should be, by comparing the user's current pointer location with its location when the drag began.\n\n<Figure\n  src=\"/images/dead-zone/dead_zone_1.png\"\n  alt=\"A diagram showing how a shape's point is calculated.\"\n  title=\"To find the shape's current point, subtract the pointer's current point and its original point and add the result to the shape's original point.\"\n/>\n\nIn that post, I mentioned that such a technique could be useful for features such as implementing a dead zone; and as we'll see, it fixes plenty of issues with dead zones.\n\n## The Dead Zone FSM\n\nWe can implement a dead zone using a finite state machine with three states: `idle`, `pointing`, and `dragging`.\n\n<Figure\n  src=\"/images/dead-zone/dead_zone_4.png\"\n  alt=\"A diagram showing how the relationships between three finite states: idle, pointing, and dragging.\"\n  title=\"The dead zone finite state machine.\"\n/>\n\nThe state machine works like this: A user starts out in the `idle` state. When a user starts pointing a shape, we transition to the `pointing` state.\n\nIn the `pointing` state, a user can either stop pointing and return to the `idle` state, or they can move their pointer. While in the `pointing` state, moving the pointer has no effect on the shape's position. If the user moves their pointer far enough from that it leaves the dead zone, then we transition to the `dragging` state.\n\nWhen we enter the `dragging` state, we update the shape's position and keep updating it whenever the user moves their pointer. From this state, a user can return to the `idle` state by ending their drag.\n\n## Getting it Right\n\nWhile a good drag zone is useful, it's important to implement it correctly. You'll know that an implementation is correct if the user's pointer location in the `dragging` state is the same, relative to the shape, as when the user started pointing the shape.\n\n<Figure\n  src=\"/images/dead-zone/dead_zone_5.png\"\n  alt=\"A diagram showing how the position of the pointer after leaving the dead zone.\"\n  title=\"On the left, the pointer is now further up into the upper-right corner; on the right, the pointer is centered in the shape.\"\n/>\n\nAnd here's where our dragging strategy matters.\n\nIf we we only using the difference between the pointer's location and its previous location, then our \"dead zone\" would be the distance of that move; allowing a slow-moving pointer to remain in that dead zone forever.\n\n<Figure\n  src=\"/images/dead-zone/dead_zone_8.mp4\"\n  alt=\"A video showing shapes being moved around.\"\n  title=\"Using the pointer event's distance to trigger the dead zone won't work with slow-moving pointers. Bad!\"\n  isVideo\n/>\n\nFurther, once we left the dead zone, we would have no way of putting the shape back where it should be. If we only began offsetting based on pointer movement, the shape will have lagged behind.\n\n<Figure\n  src=\"/images/dead-zone/dead_zone_7.mp4\"\n  alt=\"A video showing shapes being moved around.\"\n  title=\"Using the pointer's movement means a shape will lag behind the pointer once it starts dragging. Bad!\"\n  isVideo\n/>\n\nHowever, if we're comparing against the pointer's original location, then the shape will be in the right place no matter where the pointer is when it leaves the dead zone; and we'll always leave the dead zone once it's reached the minimum distance.\n\n<Figure\n  src=\"/images/dead-zone/dead_zone_9.mp4\"\n  alt=\"A video showing shapes being moved around.\"\n  title=\"The shape is always placed correctly under the pointer. Good!\"\n  isVideo\n/>\n\n## Why is this better?\n\nAs I wrote at the start of this post, a well-implemented dead zone can prevent accidental drags during clicks, which are especially common on touch devices or when the user is pointing with a stylus. Done right, a dead zone can make an app feel more intentional while being almost impossible to notice.\n\n<Figure\n  src=\"/images/dead-zone/dead_zone_6.mp4\"\n  alt=\"A video showing shapes being moved around.\"\n  title=\"Dead zones are hard to spot unless you're dragging very slowly.\"\n  isVideo\n/>\n\nIn the example aboves, we've used a generous dead zone distance in order to show the feature in action. In a real app, you might set your dead zone as low as two or three pixels: low enough that it will only last a frame or two, but high enough to catch accidental drags.\n\n## Example\n\nWant to see this in practice? Here's an [example]([https://codesandbox.io/s/dead-zone-example-1zkw9]) in React.\n\n<CodeSandbox url=\"dead-zone-example-1zkw9\" />\n","date":1634770800000,"data":{"title":"Dead Zone Dragging","date":"Thursday, 21 October 2021","hero":"/images/dead-zone/dead_zone_3.png","status":"published","description":"Improve dragging experience by adding a spooky dead zone, or a minimum distance before a shape will begin to drag."}},{"index":1,"slug":"perfect-dragging","content":"\nI recently started writing a post about [snapping](https://twitter.com/steveruizok/status/1449866480401764359) but realized I needed to write a post about dragging first.\n\n<Tweet id=\"1449866480401764359\" />\n\nIn this post, I'm going to quickly cover how to drag a shape on a canvas, or in an application that uses some kind of [zoom ui](/posts/zoom-ui). While it may seem obvious, implementing dragging in the wrong way means that other features, such as snapping, will become much more difficult to implement later on. It's worth getting it right the first time!\n\n> ðŸ‘‹ Just want to look at some code? [Click here](https://codesandbox.io/s/perfect-dragging-example-wg5u6) for the CodeSandbox.\n\n## Picking the Right Delta\n\nWhen a user drags a shape, its our job to calculcate the shape's new position based on whatever browser event we've received. On the web, this is usually a mouse move, touch move, or pointer move; but it could also be a scroll, pan, or zoom event, too.\n\n<Figure src=\"/images/dragging/dragging_3.png\" />\n\nMany applications calculate this new position by finding the pointer's movementâ€”the difference between the pointer's _current_ point and its _previous_ point)â€”and adding this to the shape's current position. While this works, it's a bad idea. :(\n\n<Figure src=\"/images/dragging/dragging_2.png\" />\n\nA far better idea is to calculate the shape's position by taking the pointer's deltaâ€”i.e. the difference between the pointer's _current_ point and the point where the drag _began_. We can then add this delta to the shape's _original_ position in order to find its new position.\n\n<Figure src=\"/images/dragging/dragging_1.png\" />\n\n## Why is this better?\n\nThere are several advantages to this approach:\n\n- You can implement a \"dead zone\" to prevent accidental drags.\n- You can update the position while scrolling during the drag.\n- You can restore a shape's position if the user cancels the drag.\n- You can freely adjust the delta with features like snapping, precision mode, or elastic bounds.\n\nIn later posts, I'll show how you could build these types of features on top of this strategy.\n\nUntil then, you'll have to trust me: in every case, the only way to implement these features is to _never_ rely on the shape's \"current\" position and _always_ compare against the shape's original position instead.\n\n## Example\n\nWant to see this in practice? Here's an [example]([https://codesandbox.io/s/perfect-dragging-example-wg5u6]) in React.\n\n<CodeSandbox url=\"perfect-dragging-example-wg5u6\" />\n","date":1634684400000,"data":{"title":"Perfect Dragging","date":"Wednesday, 20 October 2021","hero":"/images/dragging/dragging_1.png","status":"published","description":"How to drag shapes the right way. And yes, there is a wrong way! But trust me, this is the right way."}},{"index":2,"slug":"perfect-snapping","content":"\nIn this post, I'm going to walk through how you might implement one of my favorite features in design apps: snapping.\n\nIn a design app, snapping happens when you're dragging or resizing some selected on the canvas. If the app detects that your selection _almost_ aligns with some other shape, then it will adjust your selection so that it _does_ align.\n\nIf we want to implement snapping in our own app, then **what we're after is this offset**â€”the distance to move the selection so that it snaps to the right place.\n\nWe can find that offset by comparing the bounding box of our _selected_ shapes against the bounding boxes of other shapes on the page.\n\n## Get your Bounding Boxes\n\nAs a quick refresher: a bounding box is the smallest possible box that we could draw around a shape. Our bounding boxes will be \"axis-aligned\", meaning they'll never be rotatedâ€”even if the shape itself is rotated.\n\n<img src=\"/images/snapping/snapping_3.png\" />\n\nThough we could define a box using only four numbers (its `x`, `y`, `width`, and `height`), we'll want to compute some more information to save time later.\n\nWe'll define a bounding box like this:\n\n```ts\ninterface AABB {\n  minX: number\n  midX: number\n  maxX: number\n  minY: number\n  midY: number\n  maxY: number\n  width: number\n  height: number\n}\n```\n\nThis will give us enough information to compute nine points on the shape: the min, mid, and max in both dimensions.\n\n<img src=\"/images/snapping/snapping_2.png\" />\n\nWhich bounding boxes do we need to find? That's in part up to you. You can start with every shape on the canvas, then filter out the shapes that the user has selected or the shapes that are outside of the viewport.\n\nSo if our shapes look like this:\n\n```ts\ninterface Shape {\n  id: string\n  point: number[]\n  size: number[]\n}\n```\n\nThen we could find a bounding box like this:\n\n```ts\nfunction getAABB({ point: [x, y], size: [w, h] }: Shape) {\n  return {\n    minX: x,\n    midX: x + w / 2,\n    maxX: x + w,\n    minY: y,\n    midY: y + h / 2,\n    maxY: y + h,\n    width: w,\n    height: h,\n  }\n}\n```\n\nAnd if our app state looks like this:\n\n```ts\ninterface State {\n  shapes: Shape[]\n  selection: Shape[]\n  viewport: AABB\n}\n```\n\nThen with a few helper functions...\n\n```ts\nconst boundsContain = (a: AABB, b: AABB) =>\n  a.minX < b.minX && a.minY < b.minY && a.maxY > b.maxY && a.maxX > b.maxX\n\nconst boundsCollide = (a: AABB, b: AABB) =>\n  !(a.maxX < b.minX || a.minX > b.maxX || a.maxY < b.minY || a.minY > b.maxY)\n```\n\nWe could find the \"snappable\" bounding boxes like this:\n\n```ts\nfunction getSnappableAABBs(\n  shapes: Shape[],\n  selection: Shape[],\n  viewport: AABB\n) {\n  return shapes\n    .filter((shape) => !selection.includes(shape))\n    .map(getAABB)\n    .filter(\n      (bounds) =>\n        boundsContain(viewport, bounds) || boundsCollide(viewport, bounds)\n    )\n}\n```\n\nWe now have all the _other_ bounding boxes that our selection might snap to.\n\nNext, let's find the bounding box for our selected shapes.\n\nHere we'll need one more helper function:\n\n```ts\nconst expandBounds = (a: AABB, b: AABB) => {\n  const minX = Math.min(a.minX, b.minX)\n  const maxX = Math.max(a.maxX, b.maxX)\n  const minY = Math.min(a.minY, b.minY)\n  const maxY = Math.max(a.maxY, b.maxY)\n\n  return {\n    minX,\n    midX: (minX + maxX) / 2,\n    maxX,\n    minY,\n    midY: (minY + maxY) / 2,\n    maxY,\n    width: maxX - minX,\n    height: maxY - minY,\n  }\n}\n```\n\nAnd we can use it like so:\n\n```ts\nfunction getCommonAABB(shapes: Shape[]) {\n  return shapes.map(getAABB).reduce((a, b, i) => {\n    if (i === 0) return b\n    return expandBounds(a, b)\n  }, {} as AABB)\n}\n```\n\nOk! We now have all of the information we need to find our snap offset.\n\n## Finding the Snaps\n\nAs we said in the introduction, a snap happens when the selected bounding box _almost_ aligns with another shape's bounding box. Let's break that down a bit.\n\nFirst, let's say that the length of \"almost\" is 5.\n\n```ts\nconst isCloseEnough = (distance: number) => Math.abs(distance) < 5\n```\n\nOur selection can have at most two snaps: one for its `x` axis and one for its `y` axis. The selection can snap to different shapes on either axis.\n\n<img src=\"/images/snapping/snapping_4.png\" />\n\nFor _either_ axis, the selection can snap at either its `mid`, `min`, or `max`â€”and it can snap to the other shape's `mid`, `min`, or `max`, too. This gives us nine potential snaps for each direction, or eighteen total.\n\n<img src=\"/images/snapping/snapping_5.png\" />\n\nIn our code, we can define a snap like this:\n\n```ts\ninterface SnapX {\n  target: AABB\n  from: \"midX\" | \"minX\" | \"maxX\"\n  to: \"midX\" | \"minX\" | \"maxX\"\n}\n\ninterface SnapY {\n  target: AABB\n  from: \"midY\" | \"minY\" | \"maxY\"\n  to: \"midY\" | \"minY\" | \"maxY\"\n}\n```\n\nNot all snaps are equal. We want to preference snaps in this order:\n\n1. from the middle of the selection to the middle of the shape\n2. from the middle of the selection to the min or max of the shape\n3. from the min or max of the selection to the middle of the shape\n4. from the min or max of the selection to the min or max of the shape\n\nIf we define these as constants, starting with the mids:\n\n```ts\nconst xs = [\"midX\", \"minX\", \"maxX\"] as const\nconst ys = [\"midY\", \"minY\", \"maxY\"] as const\n```\n\nThen we can find our snap points like this:\n\n```ts\nfunction findSnaps(bounds: AABB, others: AABB[]) {\n  let snapX: SnapX\n  let snapY: SnapY\n\n  others.forEach((target) => {\n    xs.forEach((from) =>\n      xs.forEach((to) => {\n        if (snapX || !isCloseEnough(bounds[from] - others[to])) return\n        snapX = { target, from, to }\n      })\n    )\n\n    ys.forEach((from) =>\n      ys.forEach((to) => {\n        if (snapY || !isCloseEnough(bounds[from] - others[to])) return\n        snapY = { target, from, to }\n      })\n    )\n  })\n\n  return { snapX, snapY }\n}\n```\n\nIn the code above, we're iterating through the other shapes' bounds and, for each shape, checking all nine of our possible snaps for each axis. Once we've found a snap on an axis, we stop checking on that axis, which ensures that our middle-snaps take priority over our min or max snaps.\n\n## Finding the Offset\n\nNow that we have the snap points, we can figure out the offset. The offset is a vector: how far we'll need to move the selection bounds on each axis in order for it to align with the snapped edges.\n\n<img src=\"/images/snapping/snapping_6.png\" />\n\nTo find the offset, we can subtract the edges that snapped together. If we didn't have a snap on an axis, then that part of the offset will be zero.\n\n```ts\nfunction getOffsetFromSnaps(bounds: AABB, snapX: SnapX, snapY: SnapY) {\n  return [\n    snapX ? bounds[snapX.from] - snapX.target[snapX.to] : 0,\n    snapY ? bounds[snapY.from] - snapX.target[snapY.to] : 0,\n  ]\n}\n```\n\n## Using the Offset\n\nIn order to make use of our offset, we'll need to add it to the position of our dragging selection. In order for this to work correctly, it's important that we do our dragging the [right way](/posts/perfect-dragging).\n\n## Snap Lines\n\nFinding the snap offset is probably not enough, however. Snapping is a change to a user's choice, and polite software development demands that we never make this kind of change without giving a hint as to why we're doing it.\n\nIn other words, we want to _show_ the snap to the user, too.\n\nFor our example, we'll generate a series of sorted points. We can then use these to make the sort of \"snap lines\" you're used to from tools like Figma and Sketchâ€”but you can render them however you like.\n\n<img src=\"/images/snapping/snapping_6.png\" />\n\nWe can get those points like this:\n\n```ts\nfunction getSnapLines(bounds: AABB, snapX?: SnapX, snapY?: SnapY) {\n  const pointsX: number[][] = []\n  const pointsY: number[][] = []\n\n  if (snapX) {\n    const x = bounds[snapX.from]\n    pointsX.push([x, snapX.target.minY], [x, snapX.target.maxY])\n\n    if (snapX.from === \"midX\") {\n      pointsX.push([x, bounds.midY])\n    } else {\n      pointsX.push([x, bounds.minY], [x, bounds.maxY])\n    }\n\n    pointsX.sort((a, b) => a[1] - b[1])\n  }\n\n  if (snapY) {\n    const y = bounds[snapY.from]\n    pointsY.push([snapY.target.minX, y], [snapY.target.maxX, y])\n\n    if (snapY.from === \"midY\") {\n      pointsY.push([bounds.midY, y])\n    } else {\n      pointsY.push([bounds.minY, y], [bounds.maxY, y])\n    }\n\n    pointsY.sort((a, b) => a[0] - b[0])\n  }\n\n  return {\n    pointsX,\n    pointsY,\n  }\n}\n```\n\nAgain, we're doing something very similar for both the x and y axes. Our only exception is that, when\n","date":1634598000000,"data":{"title":"Perfect Snapping","date":"Tuesday, 19 October 2021","hero":"/images/snapping/snapping_1.png","status":"draft","description":"How to make shapes snap and align."}},{"index":3,"slug":"rotating-shapes","content":"\nEver notice in [Figma](https://figma.com) that if you rotate a few shapes and then rotate them back, they'll end up in a different place?\n\n<Figure\n  src=\"/images/rotating-shapes/figma-drift.mp4\"\n  alt=\"A video recorded from Figmashowing the change in position after rotating four selected shapes and then rotating them back.\"\n  isVideo\n/>\n\nIt's not just Figma! [Excalidraw](https://excalidraw.com) supports this kind of rotation and has the same issue.\n\n<Figure\n  src=\"/images/rotating-shapes/excalidraw-drift.mp4\"\n  alt=\"A video recorded from Excalidraw showing the change in position after rotating four selected shapes and then rotating them back.\"\n  isVideo\n/>\n\n...and so does my own project, [tldraw](https://tldraw.com), which is where I ran into the issue.\n\n<Figure\n  src=\"/images/rotating-shapes/tldraw-drift.mp4\"\n  alt=\"A video recorded from TLDraw showing the change in position after rotating four selected shapes and then rotating them back.\"\n  isVideo\n/>\n\nSide note: most other design tools don't support this kind of rotation. Shapes either rotate around their own centers or inherit rotation from a group. I wish they would though!\n\n<Figure\n  src=\"/images/rotating-shapes/pitch-rotation.mp4\"\n  alt=\"A video recorded from Excalidraw showing the change in position after rotating four selected shapes and then rotating them back.\"\n  isVideo\n/>\n\nAnyway, here's what's happening. When you start rotating a selection, you need to pick a point to rotate around. We're all using the average center of the selected shapesâ€”and we keep using this point until you stop rotating.\n\n<Figure\n  src=\"/images/rotating-shapes/center-rotate.mp4\"\n  alt=\"A video showing how selected shapes are rotated around their initial common center point.\"\n  isVideo\n/>\n\nHowever, the rotated shapes probably have a different average center; which means that your second rotation (ie to rotate things back) is pivoting around a different point. And that's what causes the change of position.\n\n<Figure\n  src=\"/images/rotating-shapes/new-centers.mp4\"\n  alt=\"A video showing how the selection's common center point changes when shapes are rotated.\"\n  isVideo\n/>\n\nHonestly, I was extremely glad to find this in Figma and other apps because I was worried it was a bug in my own rotation implementation.\n\nIt is even a bug though? It's weird that rotating a group and then rotating it back doesn't put them back in the same place. Let's fix it!\n\n<Figure\n  src=\"/images/rotating-shapes/tldraw-fixed.mp4\"\n  alt=\"A video from the tldraw app showing how the selection's common center point is preserved while the selection does not change.\"\n  isVideo\n/>\n\nAnd here's the fix: once a user starts a rotation, we hold onto the the center point; if the user rotates again, we re-use that same point; and we only give it up once the user makes a new selection.\n\n<Figure\n  src=\"/images/rotating-shapes/canva-fixed.mp4\"\n  alt=\"A video from the Canva app showing how the selection's common center point is preserved while the selection does not change.\"\n  isVideo\n/>\n\nTo their credit, [canva](https://canva.com) seems to be solving the problem is the same way. The original rotation point is preserved until a user makes a new selection.\n\nOk, that's it! Hope you enjoyed this extra-obscure edition of design tool micro-UX. If you catch any rotation-related bugs in [tldraw](https://tldraw.com), let me know!\n\n---\n\nLook familiar? This blog post was adapted from my [Twitter thread](https://twitter.com/steveruizok/status/1439581543480152069).\n\n<Tweet id=\"1439581543480152069\" />\n","date":1632006000000,"data":{"title":"Fixing the Drift in Shape Rotations","date":"Sunday, 19 September 2021","hero":"/images/rotating-shapes/hero.png","status":"published","description":"A look at an obscure bug common to drawing programs, where rotations can cause shapes to move to new positions."}},{"index":4,"slug":"pencil-tool","content":"\nEver wonder why regular pencil tools wait until after you finish drawing to smooth out your line? It's usually because the app is using a line-simplification algorithmâ€”and these sorts of algorithms aren't \"stable\" as a line is changing.\n\n<Figure\n  src=\"/images/pencil-ux/simplify-while-drawing.mp4\"\n  alt=\"A video showing a simplified line moving as a user writes the word hey.\"\n  isVideo\n/>\n\nHere's the algorithm at work, picking new points on almost every frame. Each solution is \"correct\" for each set of points but it is overall \"incorrect\" in the sense that the solutions keep changing! Try it out [here](https://codesandbox.io/s/simplified-too-often-xhpnr?file=/src/index.js).\n\n<Figure\n  src=\"/images/pencil-ux/simplify-hey-dots.mp4\"\n  alt=\"A video showing the simplified line's points as dots.\"\n  isVideo\n/>\n\nWhy simplify at all? The \"raw\" input points are often very jerky and noisy.\n\n<Figure\n  src=\"/images/pencil-ux/rough-hey-dots.mp4\"\n  alt=\"A video showing the drawing's unfiltered input points as dots.\"\n  isVideo\n/>\n\nThey don't make a very good looking line. Try it out [here](https://codesandbox.io/s/unfiltered-dots-kzgo3?file=/src/index.js).\n\n<Figure\n  src=\"/images/pencil-ux/rough-hey-line.mp4\"\n  alt=\"A video showing the drawing's unfiltered input points as a line.\"\n  isVideo\n/>\n\nWe can improve it a little by applying a low pass filter. (grey dots are the original points)\n\n<Figure\n  src=\"/images/pencil-ux/low-pass-hey-dots.mp4\"\n  alt=\"A video showing the drawing's input points as dots after a low-pass filter has been applied.\"\n  isVideo\n/>\n\nThe low-pass improves things a bit... (Try it out [here](https://codesandbox.io/s/low-pass-qvun5?file=/src/index.js))\n\n<Figure\n  src=\"/images/pencil-ux/low-pass-hey.mp4\"\n  alt=\"A video showing the drawing's input points as a line after a low-pass filter has been applied.\"\n  isVideo\n/>\n\nBut it's still a lot of data, especially if you're expecting to edit the points after the fact. So why not just wait until the end to simplify? The line doesn't change while the user draws and we get the result we want at the end, too. Try it out [here](https://codesandbox.io/s/agitated-knuth-k1dwm?file=/src/index.js).\n\n<Figure\n  src=\"/images/pencil-ux/rough-then-smooth.mp4\"\n  alt=\"A video showing the drawing's input points as a line during the drawing, then applying a simplify filter when it is completed.\"\n  isVideo\n/>\n\nIf you're in a design tool, then waiting until the end is probably fineâ€”but it's not a great experience for drawing or writing. So one of the big challenges in [perfect-freehand](https://github.com/steveruizok/perfect-freehand) was coming up with a \"stable\" way to simplify lines.\n\n<Figure\n  src=\"/images/pencil-ux/freehand-final.mp4\"\n  alt=\"A video showing the drawing's as a polygon rendered with perfect-freehand.\"\n  isVideo\n/>\n\nYou can see it at work on the corners of this curveâ€”first with the smoothing at minimum, and then with it turned up. (Try it [here](https://codesandbox.io/s/freehand-y1ihm?file=/src/index.js))\n\n<Figure\n  src=\"/images/pencil-ux/freehand-curves.mp4\"\n  alt=\"A video showing the perfect-freehand drawing simplifying points along a curve.\"\n  isVideo\n/>\n\nThis is still something I'm working on in the perfect-freehand algorithm. If you have any ideas, let me know. Or [dive into the code](https://github.com/steveruizok/perfect-freehand)!\n\n---\n\nLook familiar? This blog post was adapted from my [Twitter thread](https://twitter.com/steveruizok/status/1438847842261549061).\n\n<Tweet id=\"1438847842261549061\" />\n","date":1631833200000,"data":{"title":"Smooth Lines for Pencil Tools","date":"Friday, 17 September 2021","hero":"/images/pencil-ux/hero.png","status":"draft","description":"A dive of medium depth into why pencil tools work the way they doâ€”and how they can be improved."}},{"index":5,"slug":"zoom-ui","content":"\nIf you've used apps like Photoshop, Figma, or even Google Maps, then you're probably familiar with a \"zoom UI\". This pattern lets a user explore a \"canvas\" of content by panning around the canvas or zooming in on a specific point.\n\nIn this article, I'll walk through everything involved in implementing the pattern using an infinite canvas. I'll be using TypeScript and React as my example implementations. The concepts are generic and you should be able to apply them to whatever environment, language or framework you like best.\n\n> ðŸ‘‹ Just want to look at some code? [Click here](https://codesandbox.io/s/zoom-ui-example-ep0cf) for the CodeSandbox.\n\n# Core Concepts\n\nLet's start with some core concepts.\n\n![](/images/zoom-ui/camera-viewport-canvas.jpg \"A diagram showing the relationship between the canvas, the camera, and the viewport.\")\n\nThe first is the **canvas**. You can think of this as a fixed plane of infinite dimensions. In a creative app, the canvas holds the user's artboards, shapes or other content.\n\nSuspended in front of this plane is the **camera**. It points at the canvas.\n\nThe **screen** is where we see what the camera sees.\n\nThe **viewport** is the part of the canvas that is visible on the screen.\n\n![](/images/zoom-ui/viewport-screen.jpg \"A diagram showing the relationship between the canvas, the camera, and the viewport.\")\n\nNote that the viewport is not centered around the camera. Instead, the viewport extends _down\nand right_ from the camera.\n\nThe camera can move in three dimensions: the camera's **point** is its position along the horizontal and vertical axes; its **zoom** is its position relative to the canvas. As the camera moves, the viewport will change to reflect the new visible part of the canvas.\n\n## Converting between Screen and Canvas\n\nA zoom UI has two coordinate systems: **screen coordinates** and **canvas coordinates**. A certain point on the screen will always refer to a certain point on the canvas. The actual canvas point will depend on the camera's point and zoom.\n\nIf we model a point like this:\n\n```ts\ninterface Point {\n  x: number\n  y: number\n}\n```\n\nAnd our camera like this:\n\n```ts\ninterface Camera {\n  x: number\n  y: number\n  z: number\n}\n```\n\nThen we can turn a screen point into a canvas point like this:\n\n```ts\nfunction screenToCanvas(point: Point, camera: Camera): Point {\n  return {\n    x: point.x / camera.z - camera.x,\n    y: point.y / camera.z - camera.y,\n  }\n}\n```\n\nAnd likewise, we can turn a canvas point into a screen point:\n\n```ts\nfunction canvasToScreen(point: Point, camera: Camera): Point {\n  return {\n    x: (point.x + camera.x) * camera.z,\n    y: (point.y + camera.y) * camera.z,\n  }\n}\n```\n\n**Note**: In our model, a zoom of `1` is equal to a 100% zoom.\n\n## Finding the Viewport\n\nThe viewport is a box that represents which part of the canvas is shown on the screen. Its values refer to canvas points. To find the viewport, we construct a box by converting the upper left and bottom right points of the screen into their corresponding canvas points.\n\nIf we define a box as:\n\n```ts\ninterface Box {\n  minX: number\n  minY: number\n  maxX: number\n  maxY: number\n  width: number\n  height: number\n}\n```\n\nThen we can find our viewport box like this:\n\n```ts\nfunction getViewport(camera: Camera, box: Box): Box {\n  const topLeft = screenToCanvas({ x: box.minX, y: box.minY }, camera)\n  const bottomRight = screenToCanvas({ x: box.maxX, y: box.maxY }, camera)\n\n  return {\n    minX: topLeft.x,\n    minY: topLeft.y,\n    maxX: bottomRight.x,\n    maxY: bottomRight.y,\n    height: bottomRight.x - topLeft.x,\n    width: bottomRight.y - topLeft.y,\n  }\n}\n```\n\nIn a full screen browser app, we could find the viewport like this:\n\n```ts\nconst viewport = getViewport(camera, {\n  minX: 0,\n  minY: 0,\n  maxX: window.innerWidth,\n  maxY: window.innerHeight,\n  width: window.innerWidth,\n  height: window.innerHeight,\n})\n```\n\nOr, if our canvas was part of a webpage, we could find the viewport using its `DOMRect`. Note that in this case, scrolling would change the \"screen box\".\n\n```ts\nconst rect = document.body.getBoundingClientRect()\n\nconst viewport = getViewport(camera, {\n  minX: rect.left,\n  minY: rect.top,\n  maxX: rect.right,\n  maxY: rect.bottom,\n  width: rect.width,\n  height: rect.height,\n})\n```\n\n## Panning and Zooming\n\nWhen the camera moves along the horizontal or vertical axes, we call this movement a \"pan\". To model a pan, we adjust the camera's point by the delta in either direction. And to make the pan feel consistent, we divide the deltas by the camera's zoom.\n\n```ts\nfunction panCamera(camera: Camera, dx: number, dy: number): Camera {\n  return {\n    x: camera.x - dx / camera.z,\n    y: camera.y - dy / camera.z,\n    z: camera.z,\n  }\n}\n```\n\nWhen the camera moves toward or away from the canvas, we call this movement a \"zoom\". In our model, we also need to provide a canvas point that the camera is \"zooming toward\". Again, to make our zoom feel consistent, we adjust the zoom delta based on the current zoom.\n\n```ts\nfunction zoomCamera(camera: Camera, point: Point, dz: number): Camera {\n  const zoom = camera.z - dz * camera.z\n\n  const p1 = screenToCanvas(point, camera)\n\n  const p2 = screenToCanvas(point, { ...camera, z: zoom })\n\n  return {\n    x: camera.x + (p2.x - p1.x),\n    y: camera.y + (p2.y - p1.y),\n    z: zoom,\n  }\n}\n```\n\n## Capturing Events\n\nIn the browser, both zoom and pan events come from wheel events. By convention, we use the control key to identify a zoom. A user's device will sometimes follow this convention automatically: for example, on a MacBook trackpad, pinching will fire a WheelEvent with `ctrlKey: true`.\n\n```ts\nfunction handleWheel(event: WheelEvent) {\n  event.preventDefault()\n\n  const { clientX: x, clientY: y, deltaX, deltaY, ctrlKey } = event\n\n  if (ctrlKey) {\n    setCamera((camera) => zoomCamera(camera, { x, y }, deltaY / 100))\n  } else {\n    setCamera((camera) => panCamera(camera, deltaX, deltaY))\n  }\n}\n```\n\nSet this event on the `document.body` or the zoom UI's root container.\n\n> In the browser, wheel events often cause other changes such as scrolls or browser-level zooms. Calling `event.preventDefault()` prevents these actions. On mobile devices, you may need to cancel other touch or gesture events to avoid native behaviors.\n\nIn a React app, you might use a hook like this:\n\n```tsx\nReact.useEffect(() => {\n  const elm = ref.current\n\n  if (!elm) return\n\n  elm.addEventListener(\"wheel\", handleWheel, { passive: false })\n\n  return () => elm.removeEventListener(\"wheel\", handleWheel)\n}, [ref])\n```\n\n## Shortcuts\n\nOften you'll also want to have shortcuts for zooming in and out toward the center of the viewport.\n\n```ts\nfunction zoomCameraTo(camera: Camera, point: Point, zoom: number): Camera {\n  const p1 = screenToCanvas(point, camera)\n\n  const p2 = screenToCanvas(point, { ...camera, z: zoom })\n\n  return {\n    x: camera.x + (p2.x - p1.x),\n    y: camera.y + (p2.y - p1.y),\n    z: zoom,\n  }\n}\n```\n\nTo zoom in increments of 25%:\n\n```ts\nfunction zoomIn(camera: Camera): Camera {\n  const i = Math.round(camera.z * 100) / 25\n\n  const nextZoom = (i + 1) * 0.25\n\n  const center = { x: window.innerWidth / 2, y: window.innerHeight / 2 }\n\n  return zoomCameraTo(camera, center, camera.z - nextZoom)\n}\n```\n\n```ts\nfunction zoomOut(camera: Camera): Camera {\n  const i = Math.round(camera.z * 100) / 25\n\n  const nextZoom = (i - 1) * 0.25\n\n  const center = { x: window.innerWidth / 2, y: window.innerHeight / 2 }\n\n  return zoomCameraTo(camera, center, camera.z - nextZoom)\n}\n```\n\nAnd to reset the zoom:\n\n```ts\nfunction resetZoom(camera: Camera): Camera {\n  return zoomCamera(camera, center, camera.z - 1)\n}\n```\n\n## Applying the Camera\n\nIn the browser, the best way to apply a zoom is through CSS transforms.\n\n```ts\nconst transform = `\n  scale(${camera.z}) \n  translate(${camera.x}px, ${camera.y}px)\n`\n```\n\n> Remember that _order matters_ when writing a transform. In this case, the order is: first scale, then translate.\n\nIf you're using canvas, then you can translate the canvas instead.\n\n```ts\nctx.scale(camera.z, camera.z)\nctx.translate(camera.x, camera.y)\n```\n\n## Conclusion\n\nThat's the basics of a zoom UI. Many zoom UIs will also have the option to zooming to content or to selected content, but those functions will be different depending on how the rest of your app is set up.\n\nHere's a [CodeSandbox](https://codesandbox.io/s/zoom-ui-example-ep0cf) showing an SVG implementation for all of the code in this article.\n\nHere's a [CodeSandbox](https://codesandbox.io/s/zoom-ui-example-canvas-6j3wo) showing the same implementation with HTML canvas.\n\nEnjoy!\n","date":1628118000000,"data":{"title":"Creating a Zoom UI","date":"Thursday, 5 August 2021","hero":"/images/zoom-ui/brazil-topno-qvLhmpWIA2Y-unsplash.jpg","status":"published","description":"All the code you need to control a camera in a zoom-able, pan-able UI for an infinite canvas."}},{"index":6,"slug":"how-to-filter-an-object","content":"\nEver need to filter properties from an object? Here's how to do it.\n\nIn JavaScript:\n\n```js\nfunction filterObject(obj, fn) {\n  return Object.fromEntries(Object.entries(obj).filter(fn))\n}\n```\n\nIt's a bit trickier in TypeScript:\n\n```ts\ntype Entry<T> = {\n  [K in keyof T]: [K, T[K]]\n}[keyof T]\n\nfunction filterObject<T extends object>(\n  obj: T,\n  fn: (entry: Entry<T>, i: number, arr: Entry<T>[]) => boolean\n) {\n  return Object.fromEntries(\n    (Object.entries(obj) as Entry<T>[]).filter(fn)\n  ) as Partial<T>\n}\n```\n\nIn either case, we can use our `filterObject` helper to return a new copy of an object with certain keys removed. Our filter function works just like `Array.filter`, except that its callback function's first parameter will be the property's key value pair as array (`[key, value]`).\n\n```ts\nconst author = { name: \"Steve\", age: 93, height: 241 }\n\nconst onlySteves = filterObject(author, ([k, v]) => v === \"Steve\")\n// { name: \"Steve\" }\n\nconst onlyNumbers = filterObject(author, ([k, v]) => typeof v === \"number\")\n// { age: 93, height: 241 }\n\nconst onlyNames = filterObject(author, ([k, v]) => k === \"name\")\n// { name: \"Steve\" }\n```\n\n### Older Browsers\n\nIf you wanted to do this by hand (or perhaps in older browsers without polyfills for `Object.fromEntries` and `Object.entries`), you could also do it this way: create a shallow copy of the object, iterate once to generating the entries, and then iterate again to `delete` filtered properties.\n\n```ts\nfunction filterObject2<T extends object>(\n  obj: T,\n  fn: (entry: Entry<T>, i: number, arr: Entry<T>[]) => boolean\n): Partial<T> {\n  const next = { ...obj }\n\n  const entries: Entry<T>[] = []\n\n  for (const key in obj) {\n    entries.push([key, obj[key]])\n  }\n\n  for (let i = 0; i < entries.length; i++) {\n    const entry = entries[i]\n    if (!fn(entry, i, entries)) {\n      delete next[entry[0]]\n    }\n  }\n\n  return next\n}\n```\n\nEnjoy!\n","date":1627945200000,"data":{"title":"Filtering an Object in TypeScript","date":"Tuesday, 3 August 2021","hero":"/images/stephanie-leblanc-JLMEZxBcXCU-unsplash.jpg","status":"published","description":"How to filter properties from an object."}},{"index":7,"slug":"it-wasnt-made-to-do-that","content":"\nThis week [Figma](https://figma.com) launched their [Interactive Components ](https://help.figma.com/hc/en-us/articles/360061175334-Create-interactive-components-with-Variants) feature in beta. The response from the design community has been uh, surprising.\n\n<Tweet id=\"1367501450683834372\" />\n\nThe feature was probably designed with problems like these in mind:\n\n<Tweet id=\"1366830065468768261\" />\n\nThat hasn't stopped designers from filling my timeline with incredible, bizarre prototypes like this:\n\n<Tweet id=\"1366677421001502721\" />\n\n...and this:\n\n<Tweet id=\"1366041396092755970\" />\n\n...and even this:\n\n<Tweet id=\"1366520489578016775\" />\n\nPrototypes like these beg the question... why?\n\nOr, more specifically, **why make this in Figma?**\n\nPersonally, I'm a big fan of making stuff with the wrong tools. Projects like [Poom](https://freds72.itch.io/poom) inspire me. A long time ago, I made a kind of [Minecraft game in Framer](https://framer.cloud/TDhUi/).\n\nPushing constraints and building wild prototypes is fun, but Figma is a special case because its prototypes don't work like anything else. To learn more about why these new protoypes are exciting (or ridiculous, depending on your perspective) let's go back and look at how we got here.\n\n## Draw a Noodle\n\nIn 2017, Figma [released](https://www.figma.com/blog/figma-2-0-now-with-prototyping-and-developer-handoff/) its first set of prototyping features. It worked like this: select Frame A, draw an arrow to Frame B; and then in the preview mode, interact with Frame A to transition to Frame B.\n\n![Drawing a Noodle in Figma](/images/figma-noodle.gif)\n\nWhile the team has continued adding to this part of the app, it hasn't changed much. Prototyping in Figma has always been about **creating links between Frames**.\n\nIn fall of 2020, Figma released [Component Variants](https://www.figma.com/best-practices/creating-and-organizing-Variants/), a new feature that lets a designer create related snapshots of a Component.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-0.png\"\n  alt=\"Component Variants in Figma.\"\n/>\n\nInteractive Components brings prototyping to Component Variants, allowing a designer to **create links between Variants**.\n\n<Figure\n  src=\"/images/figma-interaction.gif\"\n  alt=\"Drawing a link between component Variants.\"\n/>\n\nIt works pretty much the same way: select Variant A, draw an arrow to Variant B; and then in the preview mode, interact with Variant A to transition _the Component_ to Variant B.\n\nTo learn why this change matters so much, let's first look at some of the problems with Figma's prototyping model.\n\n## Noodle Problems\n\nFigma's prototyping model was always good for simple click-through prototypes but it struggled with anything complex. This is because, before Interactive Components, Figma's prototype only kept track of the user's current Frame.[^1]\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-a-0.svg\"\n  alt=\"A diagram showing three Frames in Figma, with Home as the current Frame.\"\n/>\n\nClicking a link would change the current Frame.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-a-1.svg\"\n  alt=\"A diagram a link to News, with News as the new current Frame.\"\n/>\n\nAnd that was pretty much it. Building a prototype like this was easy to learn and easy to use. But it had two problems.\n\n### Problem 1: Lots of Noodles\n\nEven a small prototype has lots of links, each of which would need to be created by hand.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-a-2.svg\"\n  alt=\"A diagram showing all of the possible links.\"\n/>\n\nThere were some tricks to reduce the number of links, such as using the \"Back\" transition target or setting your links on a Component and then reusing that Component between Frames, but there was really no escaping it: prototyping in Figma meant drawing lots and lots of arrows.\n\nAnd while [I really like drawing arrows](https://github.com/steveruizok/perfect-arrows), needing to draw so many arrows made it extremely tedious to prototype even a medium-sized project in Figma.\n\n### Problem 2: Compound Noodles\n\nThere was a bigger problem, however.\n\nReal apps keep track of lots of information that describes the current \"state\" of the app. Navigation is often only a small part of that state. An app's state might also hold information such as the current user's name, their preferences and settings, or the contents of their shopping cart.\n\nBy comparison, a Figma prototype's state included _one_ piece of information: the user's current Frame.\n\nThis meant that a designer looking to model _other_ types of state, such as whether the user is in a \"light mode\" or \"dark mode\", would have to somehow achieve this complexity with only that single property to work with.\n\nThe solution? **Create a Frame for every possible state combination**.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-b-0.svg\"\n  alt=\"A diagram showing six Frames: three for light mode and three for dark mode.\"\n/>\n\nOnce a designer had modeled each state as its own Frame, a user could \"change the state\" by linking to a version that showed the correct configuration.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-b-1.svg\"\n  alt=\"A diagram showing six Frames: three for light mode and three for dark mode.\"\n/>\n\nAs you can imagine, this doesn't mix well with the first problem.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-b-2.svg\"\n  alt=\"A diagram showing 18 arrows between the six Frames.\"\n/>\n\nDifferent _kinds_ of state could make the problem even worse.\n\nAdding a \"dusk\" mode would require yet another duplication, or three more Frames, which is bad enough. But adding a _parallel_ state, such as \"logged in\", would mean duplicating the entire collectionâ€”so six more states on top of the original six, with even more arrows for each.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-b-3.svg\"\n  alt=\"A diagram showing 18 arrows between the six Frames.\"\n/>\n\nGiven enough time and coffee, I could in theory prototype a working game of checkers in Figma using only links between Framesâ€”but it would require about 500 quintillion Frames to do it, and an even greater number of links.\n\nMore realistically, once I'd built a medium-sized prototype with both light mode, dark mode, and an authentication state, I would never again change that design. Whatever I'd wired up would ship, sorry.\n\n### Enter Interactive Components\n\nGiving each Component its own state means freeing that \"current Frame\" state from its extra duties, greatly reducing the number of Frames needed to model states other than the user's actual navigation.\n\nWhile [@mingyaaa](https://twitter.com/mingyaaa)'s [game of Go](https://www.figma.com/community/file/948345806178418685) would previously have required 10<sup>172</sup> Frames (a number far greater than the number of atoms in the universe), Ming-ya could do it with just four Components, each with four Variants and a simple set of links.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-c-0.png\"\n  alt=\"A screenshot of a Figma file showing four Components.\"\n/>\n\nThe fundamental problem hasn't changed: modeling a Component with multiple properties still means creating different Variants for each combination of the Component's properties. However, by pushing the problem down into Components, Interactive Components greatly reduces the number of combinations.\n\nPrototypes that were impossible (or impractical) before are now comparitively easy to put together. That's good for everyone.\n\n## Prototyping Anything?\n\nWhile Figma's Interactive Components do expand the field of what a designer can do in a Figma prototype, there are still some major limitations. Without the ability to store, refer to, or manipulate actual data like text, numbers, or values, designers will be limited to what can be fully represented through snapshots.\n\nFor example, Design XStream's [text input](https://www.figma.com/community/file/949319444934680661) has a \"Single Letter\" Component with Variants for each possible character. The input field is a row of 26 of these components. Pressing a key changes the Component's Variant to match the key that you've pressed.\n\n<Figure\n  src=\"/images/it-wasnt-made-for-that/figma-d-0.png\"\n  alt=\"A screenshot of the Single Character Component, showing interactions.\"\n/>\n\nIn other words, Figma isn't actually storing the text you type; it's just changing the Variant of each of those Components. There's no way to use that data outside of the component.\n\n## Fun with Prototypes\n\n<Tweet id=\"1367024814062530560\" />\n\nOk, so prototyping in Figma isn't perfect. But as these prototype show, you _can_ do a lot with Interactive Components. While I'll still use other tools for more serious prototyping, Figma's limitations do make for some excellent creative constraints.\n\nInteractive Components might not have been meant to make text inputs or games, but when you give talented people simple tools to use, they can make some pretty amazing things. And I _am_ sure that the feature was made to be funâ€”and in that sense, mission accomplished!\n\n---\n\n[^1] Technically speaking, Figma also keeps track of the user's visited Frames. This \"navigation stack\" works like a stack of cards: clicking a link would add a new Frame to the stack, and going back would remove the current Frame from the stack. Whichever way you went, the Frame on top of the stack would always become the new current Frame.\n","date":1614902400000,"data":{"title":"Figma's Interactive Components Were Not Designed For This","date":"Friday, 5 March 2021","hero":"/images/figma-input.png","status":"published","description":"A survey of the bizarre prototypes designers can now make in Figma."}},{"index":8,"slug":"the-star-bug-in-every-design-tool","content":"\nAs a designer, I rely on design tools every day in order to do my work. As a designer working on _making_ design tools, I tend to look closely and critically at the tools I use. And it's tempting to ignore the thousands of things that these tools do right and instead become obsessed with the petty or meaningless faults I discover.\n\nThis is that kind of article.\n\nTake another look at this article's hero image, a screenshot from Figma showing its default star shape. Notice anything off? Well, if it looks fine to you now, I promise you that by the end of this article you will have joined me in my sufferingâ€”or at least feel an educated pity towards my plight.\n\n**Because that star is off-center**.\n\nIt's stuck to the top of its bounding box.\n\nAnd it's not just Figma. It doesn't matter what tool you use. **They're _all_ wrong.**\n\n## The Rogue's Gallery\n\nHere's the default star in Sketch:\n\n![Star shape in Sketch, off center.](/images/star-sketch.png)\n\nHere's the default star in Framer:\n\n![Star shape in Framer, off center](/images/star-framer.png)\n\nHere again is the default star in Figma:\n\n![Star shape in Figma, off center](/images/star-figma.png)\n\nHere's the default star in Proto.io:\n\n![Star shape in Proto.io, off center](/images/star-proto.png)\n\nAnd finally, while Adobe XD doesn't have a star shape, it does have a Polygon shape that can be used to create stars.\n\n![Star shape in Adobe XD, centered!](/images/star-xd.png)\n\nAlright, so not _every_ design tool has this bug.\n\nFor the rest, though, what's the problem?\n\nTo find out, we'll need to learn about how these tools draw their stars.\n\n## How to Draw a Star\n\n![Animated star-drawing algorithm.](/images/star-alg.gif)\n\nTo draw a star with _n_ points inside of a bounding box:\n\n1. Draw a circle that touches all four corners of the bounding box.\n2. Starting from the top and center, place _n_ points equally-spaced around the circle's circumference.\n3. Draw a second circle inside of the first.\n4. Starting from the bottom and center, place _n_ points equally-spaced around this circle's circumference.\n5. Draw lines that connect the points.\n","date":1599865200000,"data":{"title":"Stars are broken in your favorite design tool.","date":"Saturday, 12 September 2020","hero":"/images/star-hero.png","status":"draft","description":"Every design tool has the same bug with their star shape."}},{"index":9,"slug":"rotating-icon-button","content":"\nIf you haven't already, try changing the theme on this blog by clicking the button in the top right corner of the webpage. You'll notice a fun detail: as you cycle between the themes, the icons will \"rotate\" in from bottom to top.\n\nKinda cool, right?\n\nIn design, We call these little details _microinteractions_[^1]. Small, surprising and hopefully delightful, these animations can give an outsized amount of character to an otherwise boring, functional user interface.\n\nIn this post, I'll show you how to build a rotating icon button like mine in React. If you're just looking for the code, feel free to skip to the end or [click here](https://codesandbox.io/s/festive-fog-hnnqy?from-embed) for the code sandbox.\n\nOk, let's get started!\n\n## Setup\n\n> If you'd like to follow along, you can fork [this CodeSandbox](https://codesandbox.io/s/intelligent-goldwasser-z9szy?file=/src/App.js).\n\nLet's start by creating a new React app and adding our dependencies. For this article, I'll be using `styled-components` to handle styling and `react-feather` for icons. I'm going to use three icons: `Sun`, `CloudRain`, and `Moon`.\n\nWe'll also need a component for our button, `RotatingIconButton`. Our app is going to return this button with our three icons as its children.\n\n```jsx\nimport React from \"react\"\nimport { Sun, CloudRain, Moon } from \"react-feather\"\nimport styled from \"styled-components\"\n\nexport default function App() {\n  return (\n    <RotatingIconButton>\n      <Sun />\n      <CloudRain />\n      <Moon />\n    </RotatingIconButton>\n  )\n}\n\nfunction RotatingIconButton({ children }) {\n  return <button>{children}</button>\n}\n```\n\nThis should give us something like this:\n\n<CodeBox>\n  <button>\n    <RotatingIconButton.Sun />\n    <RotatingIconButton.CloudRain />\n    <RotatingIconButton.Moon />\n  </button>\n</CodeBox>\n\nOk, that's good for now. Let's move on to our button's styles.\n\n## Styling the Button\n\nBefore we get into our animations, let's first style up our button. By default, we want all of the button's children to be piled on top of one another in the center of the button.\n\nTo get this done, I'll create our first styled component, `Button`.\n\n```jsx\nconst Button = styled.button`\n  height: 48px;\n  width: 48px;\n  position: relative;\n  padding: 0px;\n`\n```\n\nNext, I'll create a second component, `Icon`, that we'll use to wrap our icons.\n\n```jsx\nconst Icon = styled.div`\n  position: absolute;\n  top: 0px;\n  height: 100%;\n  width: 100%;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n`\n```\n\nAnd now let's put these pieces together in the `RotatingIconButton` component.\n\n```jsx\nfunction RotatingIconButton({ children }) {\n  return (\n    <Button>\n      {React.Children.map(children, (child, i) => {\n        return <Icon>{child}</Icon>\n      })}\n    </Button>\n  )\n}\n```\n\nWe should end up with a big pile of centered icons in the middle of our button:\n\n<CodeBox>\n  <RotatingIconButton.RotatingIconButtonSimple>\n    <RotatingIconButton.Sun />\n    <RotatingIconButton.CloudRain />\n    <RotatingIconButton.Moon />\n  </RotatingIconButton.RotatingIconButtonSimple>\n</CodeBox>\n\nNow let's work out our button's state.\n\n## The Button State\n\nOut button can have any number of children but we only want it to show one child at a time. The button will need to keep track of which of these children is its _currently active_ child.\n\nWe can create this state using the `useState` React hook, and we'll store the array index of the button's currently active child. As we render each child, we can compare its index against this value to see whether that child is the currently active one.\n\n```jsx\nfunction RotatingIconButton({ children }) {\n  const [current, setCurrent] = React.useState(0)\n\n  return (\n    <Button>\n      {React.Children.map(children, (child, i) => {\n        const isCurrent = i === current\n\n        return <Icon key={i}>{child}</Icon>\n      })}\n    </Button>\n  )\n}\n```\n\nWe're not using this `isCurrent` variable yet, but we'll come back to it soon.\n\nEach time we click the button, we'll want to bump up that `current` value so that it cycles through the children. In our click event handler, we'll also need to check whether we're already at our last index (`children.length - 1`) so that we can loop back around to zero when we've reached the end.\n\n```jsx\nfunction RotatingIconButton({ children }) {\n  const [current, setCurrent] = React.useState(0)\n\n  function cycleCurrent() {\n    if (current === children.length - 1) {\n      setCurrent(0)\n    } else {\n      setCurrent(current + 1)\n    }\n  }\n\n  return (\n    <Button onClick={cycleCurrent}>\n      {React.Children.map(children, (child, i) => {\n        const isCurrent = i === current\n\n        return <Icon key={i}>{child}</Icon>\n      })}\n    </Button>\n  )\n}\n```\n\nWe now have everything we need to animate our icons.\n\n## Animating the Icons\n\nOn each render, we want our icons to perform two different animations depending on whether that icon is active or not.\n\nIf the icon is our new currently active icon, we want it to move from below the button up to the center of the button. If not, we'll instead want it to move from the center of the button to up above the button; or, if it's already above the button, to stay where it is.\n\nWe'll use the Icon element's `transfrom` property to make these moves, but we have two options for how to actually animate the element: the `transition` property and the `animation` property.\n\nLet's look at `transition` first.\n\n### Animating with Transition\n\nThe `transition` property allows us to define an animation to apply whenever certain properties change. In React, we can define a different `transform` value on each update based on `isCurrent`.\n\n```jsx\nexport function RotatingIconButton({ children }) {\n  /* snip */\n\n  return (\n    <Button onClick={cycleCurrent}>\n      {Children.map(children, (child, i) => {\n        const isCurrent = i === current\n\n        return (\n          <Icon\n            key={i}\n            style={{\n              transition: \"transform .5s\",\n              transform: `translateY(${isCurrent ? 0 : -100}%)`,\n            }}\n          >\n            {child}\n          </Icon>\n        )\n      })}\n    </Button>\n  )\n}\n```\n\nHere's what that code (with its snips unsnipped) will give us:\n\n<CodeBox>\n  <RotatingIconButton.RotatingIconButtonWithTransition>\n    <RotatingIconButton.Sun />\n    <RotatingIconButton.CloudRain />\n    <RotatingIconButton.Moon />\n  </RotatingIconButton.RotatingIconButtonWithTransition>\n</CodeBox>\n\nThat's admittedly funâ€”but it isn't what we wanted. Rather than everything moving in and out from the top, we wanted the new active icon to come in from the bottom.\n\nThis is a problem for the `transition` property. It doesn't give us a way to \"jump\" to our \"from\" position before transitioning to our \"to\" position, so we've have no way of getting from above to below without crossing back down through the middle. We could do some clever tricks here with effect hooks, `requestAnimationFrame`, and timings... but we don't have to.\n\nWe can use CSS animations instead.\n\n### Animating with CSS Animations\n\nTo use a CSS animation, we'll first need to define the animation as a set of keyframes.[^2] For this animation, we need two sets of keyframes: `riseIn` will move an element from a lower position to its default position; and `riseOut` will move the element from its default position to a higher position.\n\n```jsx\nimport styled, { keyframes } from \"styled-components\"\n\nconst riseIn = keyframes`\n  from {\n    transform: translateY(100%);\n  }\n  to {\n    transform: translateY(0%);\n  }\n`\n\nconst riseOut = keyframes`\n  from {\n    transform: translateY(0%);\n  }\n  to {\n    transform: translateY(-100%);\n  }\n`\n```\n\nNow we can modify our `Icon` styled component to use these animations. We'll pass the `Icon` component a new prop, `isCurrent`, that will determine which animation it should use.\n\n```jsx\nconst Icon = styled.div`\n  position: absolute;\n  top: 0px;\n  height: 100%;\n  width: 100%;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  animation-fill-mode: forwards;\n  animation-name: ${(props) => (props.isCurrent ? riseIn : riseOut)};\n`\n```\n\nLet's see how that looks:\n\n<CodeBox>\n  <RotatingIconButton.RotatingIconButtonWithCSSAnimation>\n    <RotatingIconButton.Sun />\n    <RotatingIconButton.CloudRain />\n    <RotatingIconButton.Moon />\n  </RotatingIconButton.RotatingIconButtonWithCSSAnimation>\n</CodeBox>\n\nIt may still look a little strange, but if we hide the overflow on the button...\n\n```jsx\nconst Button = styled.button`\n  height: 48px;\n  width: 48px;\n  position: relative;\n  padding: 0px;\n  overflow: hidden;\n`\n```\n\nThen we get this:\n\n<CodeBox>\n  <RotatingIconButton.RotatingIconButtonWithCSSAnimationNoOverflow>\n    <RotatingIconButton.Sun />\n    <RotatingIconButton.CloudRain />\n    <RotatingIconButton.Moon />\n  </RotatingIconButton.RotatingIconButtonWithCSSAnimationNoOverflow>\n</CodeBox>\n\nThere we go! We have our animation.\n\n## Final Touches\n\nThere are a few last details to take care of before I'll call this done.\n\nFirst, let's style up our button, getting rid of its background and border and giving it a hover effect.\n\n```jsx\nconst Button = styled.button`\n  height: 48px;\n  width: 48px;\n  position: relative;\n  padding: 0px;\n  overflow: hidden;\n  cursor: pointer;\n  outline: none;\n  border-radius: 4px;\n  background: transparent;\n  border: none;\n\n  &:hover {\n    background: rgba(144, 144, 144, 0.1);\n  }\n`\n```\n\n<CodeBox>\n  <RotatingIconButton.RotatingIconButtonWithCSSAnimationFinal>\n    <RotatingIconButton.Sun />\n    <RotatingIconButton.CloudRain />\n    <RotatingIconButton.Moon />\n  </RotatingIconButton.RotatingIconButtonWithCSSAnimationFinal>\n</CodeBox>\n\nThough it's probably hard to tell this deep into the article, we also need to work out how we handle our animations when the component first loads. On this first render, we don't want _any_ of our animations to fire.\n\nTo fix this, we'll need to keep track of whether we're in our first render. For this, we can use a `useRef` hook together with a `useEffect` hook that sets the ref's value back to false after the initial render.\n\n```jsx\nexport function RotatingIconButton({ children }) {\n  /* snip */\n\n  const isInitial = React.useRef(true)\n\n  React.useEffect(() => {\n    isInitial.current = false\n  }, [])\n\n  return <Button onClick={cycleCurrent}>{/* snip */}</Button>\n}\n```\n\nTo make use of this value, we'll give our `Icon` component one more prop, `isInitial`, that sets its animation duration to zero when `isInitial` is true.\n\n```jsx\nconst Icon = styled.div`\n  position: absolute;\n  top: 0px;\n  height: 100%;\n  width: 100%;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  animation-fill-mode: forwards;\n  animation-duration: ${(props) => (props.isInitial ? 0 : 400)}ms;\n  animation-name: ${(props) => (props.isCurrent ? riseIn : riseOut)};\n`\n```\n\nAnd finally we can pass `isInitial` in through the `Icon`'s props.\n\n```jsx\nexport function RotatingIconButton({ children }) {\n  /* snip */\n\n  const isInitial = React.useRef(true)\n\n  React.useEffect(() => {\n    isInitial.current = false\n  }, [])\n\n  return (\n    <Button onClick={cycleCurrent}>\n      {Children.map(children, (child, i) => {\n        const isCurrent = i === current\n\n        return (\n          <Icon key={i} isInitial={isInitial} isCurrent={isCurrent}>\n            {child}\n          </Icon>\n        )\n      })}\n    </Button>\n  )\n}\n```\n\n## Final Component\n\nAnd that's it! Here it is, our final component in a sandbox:\n\n<CodeSandbox url=\"festive-fog-hnnqy\" />\n\nNow this isn't _exactly_ how I implemented my theme switching button on this blog, but it's the basic idea. To make it work for your site, you might have to pass along events to your button through its props, especially if you plan on doing more with clicks than just switching the icon. Alternatively, you could use custom hooks inside of the component to control a theme or update the `current` state if the theme changed from elsewhere.\n\nIf the tricky part was just the animation, then you should be good to go.\n\nThanks for reading, and good luck!\n\n[^1]: A cousin of the microinteraction is something I like to call the \"fidget interaction\", like the famous [chat room gem](https://diablo.fandom.com/wiki/Chat_Gem) in the Diablo video game. While microinteractions tend to reward or acknowledge certain user behaviors, fidget interactions are pointless: they don't _do_ anything except give us something to do. Try hovering over the black box at the top left of the header.\n[^2]: We could define these keyframes in a CSS file and just reference these animations by name, but since we're already using styled-components, let's stick to its way of handling keyframes. For the regular approach, see MDN's excellent guide to [Using CSS Animations](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Animations/Using_CSS_animations).\n","date":1599606000000,"data":{"title":"Making a Rotating Icon Button in React","date":"Wednesday, 9 September 2020","hero":"/images/anastasia-taioglou-EEDLURXCpqg-unsplash.jpg","status":"published","description":"A tutorial on building my this blog's theme-switching microinteraction."}},{"index":10,"slug":"how-i-built-this-blog","content":"\nimport LightDarkSwitch from \"../../components/theme-switch\"\n\nAs a designer, I've spent my career borrowing development tools to build prototypes that needed a level of interactivity or data that couldn't be done in design tools alone. I was always more of a chainsaw artist than arborist, however, and so I skipped many of the projects that other developers start off with.\n\nRecently, as the tools have become easier and more interesting, I've started drifting moving from making models to building actual projects meant to be used in production. And I've wanted a place to write about what I'm learning...\n\nSo welcome to my first blog.[^1]\n\n## Stacking Technologies\n\nMaking a website like this blog means solving several different problems, such as how content should be turned into code, how elements of the site should be styled and themed, and how the website should get uploaded onto the internet.\n\nWhile all of the solutions need to work together, a developer can use different technologies to solve each problem. They could write their own solution for each one, but would usually choose from the thousands of free and open-source solutions shared by other experts developers.\n\nThe result is a \"stack\" of technologies that is tuned to the specific needs of the website. The stack also expresses the constraints of the project, like budget and time, as well more subjective things, like the developer's interests and their preferred ways of working.\n\nHere's my stack.\n\nI designed this blog in Figma. I've built the website using the [Next.js](https://nextjs.org/) framework and I've deployed it to [Vercel](https://vercel.com/dashboard). I've written my [React](https://reactjs.org/) components in [TypeScript](https://www.typescriptlang.org/) and I've used [Stitches](https://stitches.dev/) for styling. I write my content in [MDX](https://mdxjs.com/).\n\nIf you're after the source code, you can find that [here](https://github.com/steveruizok/personal-blog).\n\nIn the sections below, I'll describe how I built this blog. I'll first introduce the \"stack\" of technologies that I used, then I'll break down each part of this stack and explain how it works with other parts of the stack. Along the way, I'll give some insight into my reasoning behind the choices I've made.\n\n## Rendering Websites in React and Next.js\n\nLet's start with the choice to use [Next.js](https://nextjs.org/) as a framework. To learn about Next, we also need to learn a bit about React.\n\n[React](https://reactjs.org/) is a library for building user interfaces, created and maintained by Facebook. [Next.js](https://nextjs.org/) is a framework that builds on top of React in order to give developers more options in how they build and deploy websites.\n\nIn a Next project, your website's pages are defined as individual files, each containing the code for a React component that defines what is on that page. Like all React components, this page component can be made up of HTML tags, like `<p>` to describe paragraphs, as well as other reusable components, like `<Header>`s, `<Button>`s and `<Menu>`s, that you've defined elsewhere in your project.\n\n```tsx\n// pages/my-page.jsx\n\nimport Heading from \"../components/heading\"\n\nfunction MyPage() {\n  return (\n    <Layout>\n      <Title>My Blog</Title>\n      <Heading>My First Post</Heading>\n      <main>\n        <p>Welcome to my blog!</p>\n      </main>\n    </Layout>\n  )\n}\n```\n\nWhile React code is easy to read and write, browsers like Chrome and Safari can't actually read it. They only speak two languagesâ€”HTML for markup and CSS for stylingâ€”and so a component like the one above will eventually need to be \"rendered\", or turned into the HTML and CSS that the browser can actually read.\n\n```html\n<!-- my-page.html -->\n\n<html>\n  <head>\n    <title>My Blog</title>\n  </head>\n  <body>\n    <main>\n      <h1 className=\"post-header\">My First Post</h1>\n      <p>Welcome to my blog!</p>\n    </main>\n  </body>\n</html>\n```\n\nIn a \"normal\" React project, this \"rendering\" process happens on a user's machine. When a user visits a React website, their browser downloads the React code for the website along with instructions on how to turn it into HTML and CSS. The user's browser runs that code, builds the page that the user wants to see, and shows the result to the user.\n\nWhile this can result in bigger downloads and slower websites, this approach allows for highly \"dynamic\" pages that can easily render different content for different users. For example, a personalized news feed or a music app.\n\nBy contrast, a Next project is designed to create \"server rendered\" pages. Each Next project includes a \"build\" step where pages are \"pre-rendered\" into their final HTML and CSS upfront. When a user visits a page created by a Next project, their browser will only download these pre-rendered files, saving the user from having to download the whole site in order to build and render it themselves.\n\nServer-side rendering can result in much smaller downloads and faster websites for projects with little or no dynamic content[^2]. And so, because this blog has no dynamic content, that choice was easy to make.\n\n## Writing Content in MDX\n\nReact is great for creating the components of a website (things like the light mode / dark mode toggle at the top of this page) that come together to form a user interface. However, like HTML itself, React isn't a great language for long form written content, such as the content of this blog post.\n\nWriting a post in React would look something like this:\n\n```tsx\nfunction MyFirstPost() {\n  return (\n    <PostLayout\n      title=\"My First Blog Post\"\n      date=\"9/1/2020\"\n      hero=\"/images/my-hero-image.jpg\"\n    >\n      <p>Welcome to my blog!</p>\n      <h2>Introduction</h2>\n      <p>\n        My name is <a href=\"https://twitter.com/steveruizok\">Steve</a> and I'm a\n        product designer who writes about design, code, and everything in\n        between. I live in London but I'm originally from Chicago. It's been a{\" \"}\n        <i>long</i> year, hasn't it?\n      </p>\n      <p>Anyway, thanks for reading!</p>\n    </PostLayout>\n  )\n}\n```\n\nIt's not impossible, but I think it's a clunky syntax for blogging. Other people have thought so too. In 2004, [John Gruber](https://daringfireball.net/projects/markdown/) created Markdown, a much more gentle syntax that a computer could easily convert into HTML. The same content, written in Markdown, would look like this:\n\n```md\n---\ntitle: \"My First Blog Post\"\ndate: \"9/1/2020\"\nhero: \"/images/my-hero-image.jpg\"\n---\n\nWelcome to my blog!\n\n## Introduction\n\nMy name is [Steve](https://twitter.com/steveruizok) and I'm a product\ndesigner who writes about design, code, and everything in between. I\nlive in London but I'm originally from Chicago. It's been a _long_\nyear, hasn't it?\n\nAnyway, I thanks for reading!\n```\n\nThat's much easier to read, write, and edit. It also contains a section at the top, between the two `---` lines, called the file's \"frontmatter\". I'll come back to this later, but this frontmatter text allows me to define custom properties for the post, such as its title, date, and hero image, that I can use elsewhere in my layout.\n\n### Markdown to MDX\n\nWhile Markdown is great for regular written content, it's limited to _just_ written content. What if I want to include a React component like this one, right here inside of my blog post?\n\n<div\n  style={{\n    display: \"flex\",\n    justifyContent: \"center\",\n    animation: \"1s ease-in-out 1s infinite alternate bounce\",\n  }}\n>\n  <LightDarkSwitch />\n</div>\n\nAgain, I'm not the first person to feel this way.\n\nIn 2018, after a few years of early experiments, [Guillermo Rauch](@rauchg) [proposed](https://spectrum.chat/frontend/general/mdx-proposal~1021be59-2738-4511-aceb-c66921050b9a) a new syntax called MDX.[^3] In the same way that Markdown converts text to HTML, MDX would convert text to React components, thereby giving authors much more control over how their content is rendered as well as allowing for inline React components.\n\n```md\n# Example\n\nHere's a React component inside of my Markdown.\n\n<LightDarkSwitch />\n\nPretty cool, right?\n```\n\nMDX has grown into an excellent tool for web authors, and so I've chosen to use it for this blog. Using MDX also allows me to use markdown for my `index`, `archive`, and `about` pages.\n\n## Styling\n\nWhen it comes to styling, React is an extremely flexible framework.\n\nThe most basic way to style content is by defining styles in a [CSS](https://developer.mozilla.org/en-US/docs/Web/CSS) file and then attaching their class names to the HTML elements in your React components.\n\n```css\n/* styles.css */\n\n.post-link {\n  padding: 24px;\n  margin: -24px;\n}\n\n.post-link:hover {\n  background-color: #eaf4fd;\n}\n```\n\n```jsx\n// post-link.tsx\n\nfunction PostLink({ title, author }) {\n  return (\n    <a className=\"post-link\">\n      <h2>{title}</h2>\n      <p>{author}</p>\n    </a>\n  )\n}\n```\n\nWhile this approach does work, it makes certain things more difficult. For example, the syntax for sharing variables for fonts, sizes, and other foundations can be clunky and verbose. Changing themes, such as between light and dark mode, can also require broad changes to variables and stylesheets. As a website grows, it's easy to get lost in your styles.\n\nSuch complexity, clunkiness and verbosity can all make development slower, more prone to error, and produce a worse experience for both developers and users.\n\n### CSS in JS\n\nFor this reason, many developers reach for styling libraries that allow styles to be defined alongside their React components in JavaScript. The libraries take care of creating the CSS stylesheets and applying class names where needed.\n\nThere are several different styling libraries, but they all look something like this:\n\n```jsx\n// post-link.tsx\n\nconst HoverLink = styled(\"a\", {\n  padding: 24,\n  margin: -24,\n  \"&:hover\": {\n    backgroundColor: \"#eaf4fd\",\n  },\n})\n\nfunction PostLink({ title, author }) {\n  return (\n    <HoverLink>\n      <h2>{title}</h2>\n      <p>{author}</p>\n    </HoverLink>\n  )\n}\n```\n\nMore recently, other tools have built on top of these libraries in order to allow developers to define \"themes\" that can be easily swapped in and out.\n\nIn 2019, [Brent Jackson](https://twitter.com/jxnblk) defined a [theme specification](https://system-ui.com/theme/), or a pattern for defining such themes that other tools could follow. He later put this spec into practice with [theme-ui](https://theme-ui.com/theme-spec).\n\n### From Theme-UI to Stitches\n\nWhen I began this blog, I used theme-ui to define a theme and then built my components using [emotion](https://emotion.sh/), the styling library that powers theme-ui.\n\nLater on, I switched to [Stiches](http://stitches.dev), a newly released library by the team at [Modulz](https://www.modulz.app/).[^4] Like theme-ui, it follows Jackson's theme specification; however, it has its own styling engine that may work better with the project's \"static\" approach.\n\nMy site has a core configuration that defines tokens for colors, sizes, spaces and breakpoints, and two themes that overwrite the configuration's colors tokens. Both the configuration and the themes are pretty basic.\n\n```js\nconst { styled, css } = createStyled({\n  tokens: {\n    // ...\n    fontSizes: {\n      $0: \"14px\",\n      $1: \"16px\",\n      $2: \"18px\",\n      $3: \"20px\",\n      $4: \"24px\",\n      $5: \"28px\",\n    },\n    fonts: {\n      $body: \"'Fira Sans', system-ui, sans-serif\",\n      $ui: \"'Fira Sans', system-ui, sans-serif\",\n      $heading: '\"Fira Sans\", system-ui, sans-serif',\n      $display: '\"Fira Sans\", system-ui, sans-serif',\n      $monospace: '\"Fira Code\", Menlo, monospace',\n    },\n  },\n  // ...\n})\n```\n\nMy components are more complex. They include theme from the theme along with different properties defined for each breakpoint.\n\n```ts\nconst Container = styled(Grid, {\n  gridTemplateColumns: \"1fr repeat(4, auto)\",\n  gridGap: 0,\n  alignItems: \"center\",\n  justifyContent: \"space-between\",\n  fontFamily: \"$ui\",\n  mr: \"-$0\",\n  mt: 0,\n  mb: \"$5\",\n  sm: {\n    mt: \"$2\",\n    mr: \"-$1\",\n  },\n})\n```\n\nI use these styled components throughout the site, such as for the site's header and footer. I also feed these components to MDX so that it will convert my MDX content into these styled components. As a result, whenever I decide to tweak values for spacing and colors in my configuration, those changes will apply throughout the blog's pages, layout, and content.\n\n---\n\n[^1]: Sort of. In the late 2000s and early 2010s, I wrote about art in Chicago under the official-sounding name [Chicago Art Review](http://chicagoartreview.com/). The site began as a Wordpress theme. Over the years I modified the theme and tried writing my own but never with much success. The closest I'd really come to \"building a blog\" was when I built [The Visualist](http://www.thevisualist.org/), a visual arts calendar for the Chicago art community, with a design by [Chad Kouri](https://chadkouri.com/about/). That was also a Wordpress project, but the theme was more custom and pretty complex. I'm still not sure how I got it to work, but it's still running.\n[^2]: There is of course a tradeoff here: while static sites are perfect for blogs and other projects where each user will view the same content, they are harder to use for sites that need dynamic content. It can still be done, however, on a component-by-component basis; so unless _all_ of a site's content needs to be dynamic, this kind of partial SSR is probably a better choice!\n[^3]: Rauch is also responsible for this blog's framework, Next.js, as well as its deployment platform, Vercel, so it owes much to him and his collaborators.\n[^4]: What's the point of a blog if not to try out the latest tools?\n","date":1599346800000,"data":{"title":"How I Built This Blog","date":"Sunday, 6 September 2020","hero":"/images/greyson-joralemon-A1g0oeX29ec-unsplash.jpg","status":"draft","description":"A breakdown of the technical stack I used to make this blog."}}]}